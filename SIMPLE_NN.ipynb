{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example of fitting an NN in TF, just changed a couple of items.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "# USE SHIFT+TAB FOR DOC STRING IN FUNCTION\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.read_csv('train_LR.csv', sep = ',')\n",
    "housing_df = shuffle(housing_df) #make sure not pre-ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#breakup into features and labels (targets)\n",
    "processed_features = housing_df[['GrLivArea']]\n",
    "output_targets = housing_df[['SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT INTO 3 PARTS:  TRAIN, VAL, TEST\n",
    "training_examples = processed_features[0:1060]\n",
    "training_targets = output_targets[0:1060]\n",
    "\n",
    "val_examples = processed_features[1060:1260]\n",
    "val_targets = output_targets[1060:1260]\n",
    "\n",
    "test_examples = processed_features[1260:1460]\n",
    "test_targets = output_targets[1260:1460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "\n",
    "# CONFIGURE A NUMERIC FEATURE COLUMN FOR GRLIVAREA\n",
    "my_feature_columns = [tf.feature_column.numeric_column('GrLivArea')]\n",
    "\n",
    "# Define the preferred optimizer:  in this case lets use gradient descent\n",
    "#my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01) #too small, big error, now chnage on second run to 0.1\n",
    "my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "# configure the LR model without feature columns and optimizer:\n",
    "#model = tf.estimator.LinearRegressor(feature_columns=my_feature_columns, optimizer=my_optimizer)\n",
    "model = tf.estimator.DNNRegressor(feature_columns=my_feature_columns, hidden_units=[12,12], optimizer=my_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input function:\n",
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    # Convert pandas data ina a dict of np arrays\n",
    "    features = {key:np.array(value) for key, value in dict(features).items()}\n",
    "\n",
    "    # Construct a datasetj, and configure batching/reapeating.\n",
    "    ds = Dataset.from_tensor_slices((features, targets)) # warning:  2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "\n",
    "    # Shuffle the data, if specified\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=10000)\n",
    "\n",
    "    # Return the next batch of data\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model from existing data\n",
    "training = model.train(input_fn = lambda:my_input_fn(training_examples, training_targets), steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error (on training data): 71811.6214101775\n",
      "Root mean squared error (on val data): 85811.78925133696\n",
      "Root mean squared error (on test data): 59984.19457899401\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with RMSE:\n",
    "train_predictions = model.predict(input_fn = lambda: my_input_fn(training_examples, training_targets, num_epochs=1, shuffle=False))\n",
    "val_predictions = model.predict(input_fn = lambda: my_input_fn(val_examples, val_targets, num_epochs=1, shuffle=False))\n",
    "test_predictions = model.predict(input_fn = lambda: my_input_fn(test_examples, test_targets, num_epochs=1, shuffle=False))\n",
    "\n",
    "# Format predictions as np arrays so we can calc error metrics\n",
    "train_predictions = np.array([item['predictions'][0] for item in train_predictions])\n",
    "val_predictions = np.array([item['predictions'][0] for item in val_predictions])\n",
    "test_predictions = np.array([item['predictions'][0] for item in test_predictions])\n",
    "\n",
    "# print MSE and RMSE:\n",
    "mean_squared_error = metrics.mean_squared_error(train_predictions, training_targets)\n",
    "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
    "print(f'Root mean squared error (on training data): {root_mean_squared_error}')\n",
    "mean_squared_error = metrics.mean_squared_error(val_predictions, val_targets)\n",
    "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
    "print(f'Root mean squared error (on val data): {root_mean_squared_error}')\n",
    "mean_squared_error = metrics.mean_squared_error(test_predictions, test_targets)\n",
    "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
    "print(f'Root mean squared error (on test data): {root_mean_squared_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Evaluate the model with visuals:\\ntrain_sample = housing_df[0:1060].sample(30)\\nval_sample = housing_df[1060:1260].sample(10)\\ntest_sample = housing_df[1260:1460].sample(10)\\n\\n# get the min and max total_rooms values\\nx_0 = train_sample['GrLivArea'].min()\\nx_1 = train_sample['GrLivArea'].max()\\n\\n# retrieve the final weight and bias generated while training:\\nweight = model.get_variable_value('linear/linear_model/GrLivArea/weights')[0]\\nbias = model.get_variable_value('linear/linear_model/bias_weights')\\n\\n# get the predicted medeian_house_values for the min and max total_rooms values\\ny_0 = weight * x_0 + bias\\ny_1 = weight * x_1 + bias\\n\\n# plot our regression line from (x_0, y_0) to (x_1, y_1):\\nplt.plot([x_0, x_1], [y_0, y_1], c='r')\\n\\n# label the graph axes\\nplt.ylabel('SalePrice')\\nplt.xlabel('GrLivArea')\\n\\n# plot a scatter plot from our data sample\\nplt.scatter(train_sample['GrLivArea'], train_sample['SalePrice'])\\nplt.scatter(val_sample['GrLivArea'], val_sample['SalePrice'])\\nplt.scatter(test_sample['GrLivArea'], test_sample['SalePrice'])\\n\\n# display the graph\\nplt.show()\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Evaluate the model with visuals:\n",
    "train_sample = housing_df[0:1060].sample(30)\n",
    "val_sample = housing_df[1060:1260].sample(10)\n",
    "test_sample = housing_df[1260:1460].sample(10)\n",
    "\n",
    "# get the min and max total_rooms values\n",
    "x_0 = train_sample['GrLivArea'].min()\n",
    "x_1 = train_sample['GrLivArea'].max()\n",
    "\n",
    "# retrieve the final weight and bias generated while training:\n",
    "weight = model.get_variable_value('linear/linear_model/GrLivArea/weights')[0]\n",
    "bias = model.get_variable_value('linear/linear_model/bias_weights')\n",
    "\n",
    "# get the predicted medeian_house_values for the min and max total_rooms values\n",
    "y_0 = weight * x_0 + bias\n",
    "y_1 = weight * x_1 + bias\n",
    "\n",
    "# plot our regression line from (x_0, y_0) to (x_1, y_1):\n",
    "plt.plot([x_0, x_1], [y_0, y_1], c='r')\n",
    "\n",
    "# label the graph axes\n",
    "plt.ylabel('SalePrice')\n",
    "plt.xlabel('GrLivArea')\n",
    "\n",
    "# plot a scatter plot from our data sample\n",
    "plt.scatter(train_sample['GrLivArea'], train_sample['SalePrice'])\n",
    "plt.scatter(val_sample['GrLivArea'], val_sample['SalePrice'])\n",
    "plt.scatter(test_sample['GrLivArea'], test_sample['SalePrice'])\n",
    "\n",
    "# display the graph\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
